{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:00.225333Z",
     "start_time": "2019-04-13T15:14:49.205657Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "processed_data = pickle.load(open(\"../fever_processed.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep for Evidence Accumulation\n",
    "\n",
    "* The significance of a given statement as evidence to a claim/question is modelled as a classification problem\n",
    "* Any length of text (such as a sentence from a document), is appended to the claim/question in the usual way. \"CLS\" <claim/question tokens> \"SEP\" <potential/evidence tokens> \"SEP\"\n",
    "* A class is awarded to the combined string based on the following:\n",
    "    - Class 0, if the evidence tokens do not contribute to answering the question\n",
    "    - Class 1, if the evidence tokens partially answer the question\n",
    "    - Class 2, if the evidence tokens completely answer the question\n",
    "* len(claim) + len(evidence) + 3 should be <= 96 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:00.229576Z",
     "start_time": "2019-04-13T15:15:00.226955Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:50.421270Z",
     "start_time": "2019-04-13T15:15:00.231258Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108771 / 108771771108771108771108771108771108771108771108771108771108771108771 108771108771108771108771108771108771108771 108771108771108771108771108771108771108771 108771 108771108771108771 108771 108771108771108771108771108771108771108771108771108771108771/ 108771/ 108771108771108771108771108771 108771 108771 108771 108771 108771 108771 108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771 108771108771108771108771 108771 108771 / 108771108771108771 108771 108771108771108771108771108771108771108771108771 108771 108771 108771108771108771108771108771108771108771108771 108771108771108771 108771108771108771108771108771108771108771 108771108771108771108771108771108771108771108771108771108771 108771108771108771 108771 / 108771108771108771 108771108771108771108771108771 108771108771108771 108771108771108771108771108771108771108771\r"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "classes = []\n",
    "import numpy as np\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def make_data(claim, evidence):\n",
    "    _ftokens = [\"[CLS]\"]\n",
    "    _ftokens.extend(claim)\n",
    "    _ftokens.append(\"[SEP]\")\n",
    "    _ftokens.extend(evidence)\n",
    "    _ftokens.append(\"[SEP]\")\n",
    "    while(len(_ftokens) < max_len):\n",
    "        _ftokens.append(\"[PAD]\")\n",
    "    _ftokens = _ftokens[:max_len]\n",
    "    segments = np.ones((max_len,))\n",
    "    segments[:len(claim) + 2] = 0\n",
    "    tokens = tokenizer.convert_tokens_to_ids(_ftokens)\n",
    "    return (tokens, segments)\n",
    "\n",
    "counter = 0\n",
    "for line in processed_data:\n",
    "    counter += 1\n",
    "    print(counter, \"/\", len(processed_data), end=\"\\r\")\n",
    "    for evidence in line[\"processed\"][\"evidentiary\"]:\n",
    "        lines.append(make_data(line[\"processed\"][\"claim\"], evidence))\n",
    "        if (len(line[\"processed\"][\"evidentiary\"]) == 1):\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(2)\n",
    "    for evidence in line[\"processed\"][\"non_evidentiary\"]:\n",
    "        lines.append(make_data(line[\"processed\"][\"claim\"], evidence))\n",
    "        classes.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:50.783232Z",
     "start_time": "2019-04-13T15:15:50.422998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points =  1605875\n",
      "Of which evidentiary: 201060\n",
      "Total training data points =  1445287\n",
      "Of which evidentiary: 180997\n",
      "Total testing data points =  160588\n",
      "Of which evidentiary: 20063\n"
     ]
    }
   ],
   "source": [
    "print(\"Total data points = \", len(classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(classes))\n",
    "\n",
    "training_lines = lines[:-len(classes)//10]\n",
    "training_classes = classes[:-len(classes)//10]\n",
    "\n",
    "print(\"Total training data points = \", len(training_classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(training_classes))\n",
    "\n",
    "training_evidentiary_indices = [i for i in range(len(training_classes)) if training_classes[i] > 0 ]\n",
    "training_nonevidentiary_indices = [i for i in range(len(training_classes)) if training_classes[i] == 0]\n",
    "\n",
    "testing_lines = lines[-len(classes)//10:]\n",
    "testing_classes = classes[-len(classes)//10:]\n",
    "\n",
    "testing_evidentiary_indices = [i for i in range(len(testing_classes)) if testing_classes[i] > 0 ]\n",
    "testing_nonevidentiary_indices = [i for i in range(len(testing_classes)) if testing_classes[i] == 0]\n",
    "\n",
    "print(\"Total testing data points = \", len(testing_classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(testing_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Fact Extraction (ReFE)\n",
    "\n",
    "* Going by the paper and the documentation, when fine-tuning bert for classification tasks, only the output of the CLS tag (index 0) needs to be used. We can ignore the rest\n",
    "* Aim here is to make it look to BERT like an entailment task. Since we are not really worried about the truth value of the claim, all we need to do is decide if a given sentence provides evidence to the claim or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:56.267034Z",
     "start_time": "2019-04-13T15:15:56.262800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_pretrained_bert import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:58.964692Z",
     "start_time": "2019-04-13T15:15:56.945967Z"
    }
   },
   "outputs": [],
   "source": [
    "#Aim below is to always present a balanced training set. \n",
    "\n",
    "def getTrainingBatch(bs = 64, validation = False):\n",
    "    \n",
    "    evidentiary = training_evidentiary_indices\n",
    "    non_evidentiary = training_nonevidentiary_indices\n",
    "    source = training_lines\n",
    "    source_classes = training_classes\n",
    "    \n",
    "    if (validation):\n",
    "        evidentiary = testing_evidentiary_indices\n",
    "        non_evidentiary = testing_nonevidentiary_indices\n",
    "        source = testing_lines\n",
    "        source_classes = testing_classes\n",
    "    \n",
    "    ev_total = bs // 8\n",
    "    nev_total = bs - ev_total\n",
    "    x = np.random.randint(0, len(evidentiary), (ev_total))\n",
    "    x = np.asarray(evidentiary)[x]\n",
    "    _base_tokens = [source[index][0] for index in x]\n",
    "    _segment_tokens = [source[index][1] for index in x]\n",
    "    _classes = [source_classes[index] for index in x]\n",
    "    \n",
    "    x = np.random.randint(0, len(non_evidentiary), (nev_total))\n",
    "    x = np.asarray(non_evidentiary)[x]\n",
    "    _base_tokens_ne = [source[index][0] for index in x]\n",
    "    _segment_tokens_ne = [source[index][1] for index in x]\n",
    "    _classes_ne = [source_classes[index] for index in x]\n",
    "    \n",
    "    _base_tokens.extend(_base_tokens_ne)\n",
    "    _segment_tokens.extend(_segment_tokens_ne)\n",
    "    _classes.extend(_classes_ne)\n",
    "        \n",
    "    final_seq = [i for i in range(bs)]\n",
    "    np.random.shuffle(final_seq)\n",
    "    \n",
    "    tokens = []\n",
    "    segments = []\n",
    "    classes = []\n",
    "    for index in final_seq:\n",
    "        tokens.append(_base_tokens[index])\n",
    "        segments.append(_segment_tokens[index])\n",
    "        classes.append(_classes[index])\n",
    "    \n",
    "    tokens = torch.LongTensor(tokens).cuda()\n",
    "    segments = torch.LongTensor(segments).cuda()\n",
    "    classes = torch.LongTensor(classes).cuda()\n",
    "    att_mask = tokens != 0\n",
    "    \n",
    "    return tokens, segments, att_mask, classes\n",
    "    \n",
    "tokens, segments, att_mask, classes = getTrainingBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:16:01.538854Z",
     "start_time": "2019-04-13T15:16:01.529066Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReFE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReFE, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.out = torch.nn.Linear(768,3)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, inputs, segments, attention_masks):\n",
    "        f, _ = self.bert(inputs, \n",
    "                         token_type_ids=segments, \n",
    "                         attention_mask=attention_masks, \n",
    "                         output_all_encoded_layers=False)\n",
    "        out_ = self.out(self.dropout(f[:,0,:]))        \n",
    "        return out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:16:07.964348Z",
     "start_time": "2019-04-13T15:16:02.426051Z"
    }
   },
   "outputs": [],
   "source": [
    "network = ReFE()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Friends dont let friends use batch sizes > 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "lossFn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(network, bs=96, num_batches=5):\n",
    "    \n",
    "    classes = torch.LongTensor([]).cuda()\n",
    "    preds = torch.FloatTensor([]).cuda()\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_batches):\n",
    "            tokens, segments, att_mask, classes_ = getTrainingBatch(bs=bs, validation=True)\n",
    "            y_ = network.forward(tokens, segments, att_mask)\n",
    "            classes = torch.cat([classes, classes_], dim=0)\n",
    "            preds = torch.cat([preds, y_], dim=0)\n",
    "        evidences = classes >= 1\n",
    "        non_evidences = classes == 0\n",
    "        loss1 = lossFn(F.log_softmax(preds[evidences], dim=-1), classes[evidences].cuda())\n",
    "        loss2 = lossFn(F.log_softmax(preds[non_evidences], dim = -1), classes[non_evidences].cuda())\n",
    "        f_loss = 0.75*loss1 + 0.25*loss2\n",
    "        pred = torch.max(preds, dim=-1)[1]\n",
    "        acc = torch.sum(pred == classes)\n",
    "        acc = acc.cpu().numpy()/(bs*num_batches)\n",
    "        positives = torch.sum(pred[evidences] == classes[evidences])\n",
    "        return f_loss.data.item(), acc, positives.cpu().numpy()/torch.sum(evidences).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T15:16:08.840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 10 Loss: 1.07917\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/.conda/envs/ml/lib/python3.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type ReFE. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Loss: 1.03382\n",
      "\tOverall Validation Accuracy: 0.15 ; and for evidence only: 0.64\n",
      "Epoch: 2 Batch: 10 Loss: 0.81056\n",
      "\tValidation Loss: 1.20604\n",
      "\tOverall Validation Accuracy: 0.09 ; and for evidence only: 0.62\n",
      "Epoch: 3 Batch: 10 Loss: 1.43551\n",
      "\tValidation Loss: 1.0093\n",
      "\tOverall Validation Accuracy: 0.19 ; and for evidence only: 0.6\n",
      "Epoch: 4 Batch: 10 Loss: 1.08076\n",
      "\tValidation Loss: 1.01069\n",
      "\tOverall Validation Accuracy: 0.32 ; and for evidence only: 0.55\n",
      "Epoch: 5 Batch: 10 Loss: 1.08833\n",
      "\tValidation Loss: 1.00468\n",
      "\tOverall Validation Accuracy: 0.28 ; and for evidence only: 0.56\n"
     ]
    }
   ],
   "source": [
    "def Train(network, bs = 24, epochs=30, batches_per_epoch=10000):\n",
    "    epoch_losses = []\n",
    "    epoch_vals = []\n",
    "    epoch_accs = []\n",
    "    epoch_evid = []\n",
    "    val_min = 1000\n",
    "    for k in range(epochs):\n",
    "        batch_losses = []\n",
    "        for i in range(batches_per_epoch):\n",
    "            tokens, segments, att_mask, classes = getTrainingBatch(bs=bs)\n",
    "            y_ = network.forward(tokens, segments, att_mask)\n",
    "            evidences = classes >= 1\n",
    "            non_evidences = classes == 0\n",
    "            optimizer.zero_grad()\n",
    "            loss1 = lossFn(F.log_softmax(y_[evidences], dim=-1), classes[evidences].cuda())\n",
    "            loss2 = lossFn(F.log_softmax(y_[non_evidences], dim = -1), classes[non_evidences].cuda())\n",
    "            f_loss = 0.75*loss1 + 0.25*loss2\n",
    "            batch_losses.append(f_loss.data.item())\n",
    "            print(\"Epoch:\", k+1, \n",
    "                  \"Batch:\", i+1, \n",
    "                  \"Loss:\", np.round(np.mean(batch_losses),5), \n",
    "                  end=\"\\r\")\n",
    "            f_loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_losses.append(np.mean(batch_losses))\n",
    "        val_loss, acc, evid_acc = validate(network, num_batches=10)\n",
    "        \n",
    "        epoch_vals.append(val_loss)\n",
    "        epoch_accs.append(acc)\n",
    "        epoch_evid.append(evid_acc)\n",
    "        \n",
    "        print(\"\\n\\tValidation Loss:\", np.round(val_loss,5))\n",
    "        print(\"\\tOverall Validation Accuracy:\", np.round(acc,2), \"; and for evidence only:\", np.round(evid_acc,2))\n",
    "        \n",
    "        if (val_loss < val_min):\n",
    "            print(\"\\tSaving a better model...\")\n",
    "            torch.save(network, \"./ReFE_val_save.h5\")\n",
    "            val_min = val_loss\n",
    "        \n",
    "        with open(\"./training_cycle.json\", \"w\") as f:            \n",
    "            f.write(json.dumps(\n",
    "                {\n",
    "                    \"training_losses\":epoch_losses,\n",
    "                    \"validation_losses\":epoch_vals,\n",
    "                    \"validation_accuracy\":epoch_accs,\n",
    "                    \"evidence_accuracy\":epoch_evid        \n",
    "                }\n",
    "            ))\n",
    "            f.close()\n",
    "\n",
    "#Train(network.to(\"cuda\"), bs=96, epochs=75, batches_per_epoch=1000)\n",
    "Train(network.to(\"cuda\"), bs=10, epochs=5, batches_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
