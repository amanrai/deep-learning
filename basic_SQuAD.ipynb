{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T09:20:31.672062Z",
     "start_time": "2019-04-11T09:20:31.344023Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T09:20:34.252711Z",
     "start_time": "2019-04-11T09:20:31.673831Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = pickle.load(open(\"./squad_processed_1.1.pickle\", \"rb\"))\n",
    "data = np.asarray(all_data[len(all_data) // 5:])\n",
    "validation_data = np.asarray(all_data[: len(all_data) // 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T09:20:34.257823Z",
     "start_time": "2019-04-11T09:20:34.254432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87506\n",
      "70005\n"
     ]
    }
   ],
   "source": [
    "print(len(all_data))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T09:20:34.269458Z",
     "start_time": "2019-04-11T09:20:34.259518Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBatch(bs = 64, validation=False):\n",
    "    _use_data = data\n",
    "    if (validation == True):\n",
    "        _use_data = validation_data\n",
    "    indices = np.random.randint(0, len(_use_data), (bs,))\n",
    "    batch = np.asarray(data)[indices]\n",
    "    #print(len(batch))\n",
    "    #print(batch)\n",
    "    inputs = torch.LongTensor([dp[\"data\"][\"tokens\"] for dp in batch]).cuda()\n",
    "    inputs = inputs[:,:384]\n",
    "    attention_masks = inputs != 0 #works like numpy does.\n",
    "    segments = torch.LongTensor([dp[\"data\"][\"segments\"] for dp in batch]).cuda()\n",
    "    segments = segments[:,:384]\n",
    "    start_ = torch.LongTensor([dp[\"answer_start\"] for dp in batch]).cuda()\n",
    "    end_ = torch.LongTensor([dp[\"answer_end\"] for dp in batch]).cuda()\n",
    "    return inputs, segments, attention_masks, start_, end_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T09:20:37.336061Z",
     "start_time": "2019-04-11T09:20:35.483663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 384]) torch.Size([3, 384]) torch.Size([3]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "i, se, att, st, en =  getBatch(bs=3)\n",
    "print(i.size(), se.size(), st.size(), en.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T09:20:38.185747Z",
     "start_time": "2019-04-11T09:20:38.178991Z"
    }
   },
   "outputs": [],
   "source": [
    "class SQuADHead(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                num_bert_layers=1,\n",
    "                backprop_thru_bert=False,\n",
    "                internal_dim = 256                \n",
    "                ):\n",
    "        super(SQuADHead, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\").cuda()\n",
    "        self.out = torch.nn.Linear(768,2)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, inputs, segments, attention_masks):\n",
    "        f, _ = self.bert(inputs, segments, attention_masks, output_all_encoded_layers=False)\n",
    "        out_ = self.out(self.dropout(f))\n",
    "        start_, end_ = torch.split(out_, 1, dim=-1)\n",
    "        return start_.squeeze(), end_.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:50:03.763932Z",
     "start_time": "2019-04-11T09:20:38.967616Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Gradient overflow.  Skipping step, reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, reducing loss scale to 16384.0\n",
      "Epoch: 2 Batch: 1605 Start Loss: 0.69824 End Loss: 0.61946\r"
     ]
    }
   ],
   "source": [
    "model = SQuADHead().cuda()\n",
    "loss = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "from apex.fp16_utils import FP16_Optimizer\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "#optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=False, static_loss_scale=128.0)\n",
    "\n",
    "def Train(network, epochs=10, batches_per_epoch=3000, bs=20):\n",
    "    start_losses = []\n",
    "    end_losses = []\n",
    "    for j in range(epochs):\n",
    "        for k in range(batches_per_epoch):\n",
    "            i, se, att, st, en = getBatch(bs=bs)\n",
    "            st_, en_ = model.forward(i, se, att)\n",
    "            items_to_use = en < 384\n",
    "            st_ = st_[items_to_use]\n",
    "            en_ = en_[items_to_use]\n",
    "            st = st[items_to_use]\n",
    "            en = en[items_to_use]\n",
    "            optimizer.zero_grad()\n",
    "            loss1 = loss(F.log_softmax(st_, dim=-1), st)\n",
    "            loss2 = loss(F.log_softmax(en_, dim=-1), en)\n",
    "            start_losses.append(loss1.data.item())\n",
    "            end_losses.append(loss2.data.item())\n",
    "\n",
    "            net_loss = (loss1 + loss2)/2\n",
    "            with amp.scale_loss(net_loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \"\"\"\n",
    "            with amp.scale_loss(loss2, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            #loss2.backward()\n",
    "            \"\"\"\n",
    "            optimizer.step()\n",
    "            start_losses = start_losses[-1000:]\n",
    "            end_losses = end_losses[-1000:]\n",
    "            print(\"Epoch:\", j, \"Batch:\", k, \n",
    "                  \"Start Loss:\", np.round(np.mean(start_losses), 5), \n",
    "                  \"End Loss:\", np.round(np.mean(end_losses), 5), end=\"\\r\")\n",
    "\n",
    "Train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T08:16:54.525732Z",
     "start_time": "2019-04-11T08:16:54.521558Z"
    }
   },
   "outputs": [],
   "source": [
    "print(start_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
