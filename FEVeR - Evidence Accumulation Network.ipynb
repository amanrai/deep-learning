{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:00.225333Z",
     "start_time": "2019-04-13T15:14:49.205657Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "processed_data = pickle.load(open(\"../fever_processed.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep for Evidence Accumulation\n",
    "\n",
    "* The significance of a given statement as evidence to a claim/question is modelled as a classification problem\n",
    "* Any length of text (such as a sentence from a document), is appended to the claim/question in the usual way. \"CLS\" <claim/question tokens> \"SEP\" <potential/evidence tokens> \"SEP\"\n",
    "* A class is awarded to the combined string based on the following:\n",
    "    - Class 0, if the evidence tokens do not contribute to answering the question\n",
    "    - Class 1, if the evidence tokens partially answer the question\n",
    "    - Class 2, if the evidence tokens completely answer the question\n",
    "* len(claim) + len(evidence) + 3 should be <= 96 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:00.229576Z",
     "start_time": "2019-04-13T15:15:00.226955Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:50.421270Z",
     "start_time": "2019-04-13T15:15:00.231258Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108771 / 108771771108771108771108771108771108771 108771 108771 108771108771 108771108771108771108771108771108771108771 108771108771108771108771108771108771108771108771 108771108771108771108771108771108771108771108771/ 108771108771108771 108771108771108771108771 108771108771 108771108771108771108771108771108771108771108771108771 108771108771108771108771108771108771/ 108771108771 108771108771108771108771 108771108771108771 108771108771108771108771 108771/ 108771 108771108771108771 108771108771108771 108771108771 108771108771108771 108771108771108771/ 108771108771 / 108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771 108771 108771\r"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "classes = []\n",
    "import numpy as np\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def make_data(claim, evidence):\n",
    "    _ftokens = [\"[CLS]\"]\n",
    "    _ftokens.extend(claim)\n",
    "    _ftokens.append(\"[SEP]\")\n",
    "    _ftokens.extend(evidence)\n",
    "    _ftokens.append(\"[SEP]\")\n",
    "    while(len(_ftokens) < max_len):\n",
    "        _ftokens.append(\"[PAD]\")\n",
    "    _ftokens = _ftokens[:max_len]\n",
    "    segments = np.ones((max_len,))\n",
    "    segments[:len(claim) + 2] = 0\n",
    "    tokens = tokenizer.convert_tokens_to_ids(_ftokens)\n",
    "    return (tokens, segments)\n",
    "\n",
    "counter = 0\n",
    "for line in processed_data:\n",
    "    counter += 1\n",
    "    print(counter, \"/\", len(processed_data), end=\"\\r\")\n",
    "    for evidence in line[\"processed\"][\"evidentiary\"]:\n",
    "        lines.append(make_data(line[\"processed\"][\"claim\"], evidence))\n",
    "        if (len(line[\"processed\"][\"evidentiary\"]) == 1):\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(2)\n",
    "    for evidence in line[\"processed\"][\"non_evidentiary\"]:\n",
    "        lines.append(make_data(line[\"processed\"][\"claim\"], evidence))\n",
    "        classes.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:50.783232Z",
     "start_time": "2019-04-13T15:15:50.422998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points =  1605875\n",
      "Of which evidentiary: 201060\n",
      "Total training data points =  1445287\n",
      "Of which evidentiary: 180997\n",
      "Total testing data points =  160588\n",
      "Of which evidentiary: 20063\n"
     ]
    }
   ],
   "source": [
    "print(\"Total data points = \", len(classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(classes))\n",
    "\n",
    "training_lines = lines[:-len(classes)//10]\n",
    "training_classes = classes[:-len(classes)//10]\n",
    "\n",
    "print(\"Total training data points = \", len(training_classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(training_classes))\n",
    "\n",
    "training_evidentiary_indices = [i for i in range(len(training_classes)) if training_classes[i] > 0 ]\n",
    "training_nonevidentiary_indices = [i for i in range(len(training_classes)) if training_classes[i] == 0]\n",
    "\n",
    "testing_lines = lines[-len(classes)//10:]\n",
    "testing_classes = classes[-len(classes)//10:]\n",
    "\n",
    "testing_evidentiary_indices = [i for i in range(len(testing_classes)) if testing_classes[i] > 0 ]\n",
    "testing_nonevidentiary_indices = [i for i in range(len(testing_classes)) if testing_classes[i] == 0]\n",
    "\n",
    "print(\"Total testing data points = \", len(testing_classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(testing_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Fact Extraction (ReFE)\n",
    "\n",
    "* Going by the paper and the documentation, when fine-tuning bert for classification tasks, only the output of the CLS tag (index 0) needs to be used. We can ignore the rest\n",
    "* Aim here is to make it look to BERT like an entailment task. Since we are not really worried about the truth value of the claim, all we need to do is decide if a given sentence provides evidence to the claim or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:56.267034Z",
     "start_time": "2019-04-13T15:15:56.262800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_pretrained_bert import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:58.964692Z",
     "start_time": "2019-04-13T15:15:56.945967Z"
    }
   },
   "outputs": [],
   "source": [
    "#Aim below is to always present a balanced training set. \n",
    "\n",
    "def getTrainingBatch(bs = 64, validation = False):\n",
    "    \n",
    "    evidentiary = training_evidentiary_indices\n",
    "    non_evidentiary = training_nonevidentiary_indices\n",
    "    source = training_lines\n",
    "    source_classes = training_classes\n",
    "    \n",
    "    if (validation):\n",
    "        evidentiary = testing_evidentiary_indices\n",
    "        non_evidentiary = testing_nonevidentiary_indices\n",
    "        source = testing_lines\n",
    "        source_classes = testing_classes\n",
    "    \n",
    "    ev_total = bs // 8\n",
    "    nev_total = bs - ev_total\n",
    "    x = np.random.randint(0, len(evidentiary), (ev_total))\n",
    "    x = np.asarray(evidentiary)[x]\n",
    "    _base_tokens = [source[index][0] for index in x]\n",
    "    _segment_tokens = [source[index][1] for index in x]\n",
    "    _classes = [source_classes[index] for index in x]\n",
    "    \n",
    "    x = np.random.randint(0, len(non_evidentiary), (nev_total))\n",
    "    x = np.asarray(non_evidentiary)[x]\n",
    "    _base_tokens_ne = [source[index][0] for index in x]\n",
    "    _segment_tokens_ne = [source[index][1] for index in x]\n",
    "    _classes_ne = [source_classes[index] for index in x]\n",
    "    \n",
    "    _base_tokens.extend(_base_tokens_ne)\n",
    "    _segment_tokens.extend(_segment_tokens_ne)\n",
    "    _classes.extend(_classes_ne)\n",
    "        \n",
    "    final_seq = [i for i in range(bs)]\n",
    "    np.random.shuffle(final_seq)\n",
    "    \n",
    "    tokens = []\n",
    "    segments = []\n",
    "    classes = []\n",
    "    for index in final_seq:\n",
    "        tokens.append(_base_tokens[index])\n",
    "        segments.append(_segment_tokens[index])\n",
    "        classes.append(_classes[index])\n",
    "    \n",
    "    tokens = torch.LongTensor(tokens).cuda()\n",
    "    segments = torch.LongTensor(segments).cuda()\n",
    "    classes = torch.LongTensor(classes).cuda()\n",
    "    att_mask = tokens != 0\n",
    "    \n",
    "    return tokens, segments, att_mask, classes\n",
    "    \n",
    "tokens, segments, att_mask, classes = getTrainingBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:16:01.538854Z",
     "start_time": "2019-04-13T15:16:01.529066Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReFE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReFE, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.out = torch.nn.Linear(768,3)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, inputs, segments, attention_masks):\n",
    "        f, pooled = self.bert(inputs, \n",
    "                         token_type_ids=segments, \n",
    "                         attention_mask=attention_masks, \n",
    "                         output_all_encoded_layers=False)\n",
    "        out_ = self.out(self.dropout(pooled))        \n",
    "        return out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epoch_vals = []\n",
    "epoch_accs = []\n",
    "epoch_evid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_from_prev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:16:07.964348Z",
     "start_time": "2019-04-13T15:16:02.426051Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "network = None\n",
    "if (continue_from_prev):\n",
    "    network = torch.load(\"./ReFE_val_save.h5\")\n",
    "    tcycle = None\n",
    "    with open(\"./saved_model_training_cycle.json\", \"r\") as f:\n",
    "        tcycle = json.loads(f.read())\n",
    "    epoch_losses = tcycle[\"training_losses\"][:-2]\n",
    "    epoch_vals = tcycle[\"validation_losses\"][:-2]\n",
    "    epoch_accs = tcycle[\"validation_accuracy\"][:-2]\n",
    "    epoch_evid = tcycle[\"evidence_accuracy\"][:-2]\n",
    "else:\n",
    "    network = ReFE()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Friends dont let friends use batch sizes > 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "lossFn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trg_losses = []\n",
    "ne_training_losses = []\n",
    "\n",
    "def getLoss(pred, actual, lossFn):\n",
    "    evidences = actual >= 1\n",
    "    non_evidences = actual == 0\n",
    "    loss1 = lossFn(F.log_softmax(pred[evidences], dim=-1), actual[evidences].cuda())\n",
    "    loss2 = lossFn(F.log_softmax(pred[non_evidences], dim = -1), actual[non_evidences].cuda())\n",
    "    e_trg_losses.append(loss1)\n",
    "    ne_training_losses.append(loss2)\n",
    "    return (loss1+loss2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(network, bs=100, num_batches=5):\n",
    "    \n",
    "    classes = torch.LongTensor([]).cuda()\n",
    "    preds = torch.FloatTensor([]).cuda()\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_batches):\n",
    "            tokens, segments, att_mask, classes_ = getTrainingBatch(bs=bs, validation=True)\n",
    "            y_ = network.forward(tokens, segments, att_mask)\n",
    "            classes = torch.cat([classes, classes_], dim=0)\n",
    "            preds = torch.cat([preds, y_], dim=0)\n",
    "        \n",
    "        \"\"\"\n",
    "        evidences = classes >= 1\n",
    "        non_evidences = classes == 0\n",
    "        \n",
    "        loss1 = lossFn(F.log_softmax(preds[evidences], dim=-1), classes[evidences].cuda())\n",
    "        loss2 = lossFn(F.log_softmax(preds[non_evidences], dim = -1), classes[non_evidences].cuda())\n",
    "        f_loss = 0.75*loss1 + 0.25*loss2\n",
    "        \"\"\"\n",
    "        f_loss = getLoss(preds, classes)\n",
    "        pred = torch.max(preds, dim=-1)[1]\n",
    "        acc = torch.sum(pred == classes)\n",
    "        acc = acc.cpu().numpy()/(bs*num_batches)\n",
    "        positives = torch.sum(pred[evidences] == classes[evidences])\n",
    "        \n",
    "        return f_loss.data.item(), acc, positives.cpu().numpy()/torch.sum(evidences).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T15:16:08.840Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1000 Loss: 0.61113\n",
      "\tValidation Loss: 0.53415\n",
      "\tOverall Validation Accuracy: 0.82 ; and for evidence only: 0.7\n",
      "\tSaving a better model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/.conda/envs/ml/lib/python3.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type ReFE. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 1000 Loss: 0.50894\n",
      "\tValidation Loss: 0.48041\n",
      "\tOverall Validation Accuracy: 0.81 ; and for evidence only: 0.81\n",
      "\tSaving a better model...\n",
      "Epoch: 3 Batch: 1000 Loss: 0.4756\n",
      "\tValidation Loss: 0.48892\n",
      "\tOverall Validation Accuracy: 0.82 ; and for evidence only: 0.78\n",
      "Epoch: 4 Batch: 1000 Loss: 0.45501\n",
      "\tValidation Loss: 0.52622\n",
      "\tOverall Validation Accuracy: 0.83 ; and for evidence only: 0.81\n",
      "Epoch: 5 Batch: 1000 Loss: 0.44417\n",
      "\tValidation Loss: 0.44061\n",
      "\tOverall Validation Accuracy: 0.78 ; and for evidence only: 0.81\n",
      "\tSaving a better model...\n",
      "Epoch: 6 Batch: 1000 Loss: 0.42706\n",
      "\tValidation Loss: 0.5241\n",
      "\tOverall Validation Accuracy: 0.79 ; and for evidence only: 0.78\n",
      "Epoch: 7 Batch: 1000 Loss: 0.41246\n",
      "\tValidation Loss: 0.58862\n",
      "\tOverall Validation Accuracy: 0.84 ; and for evidence only: 0.74\n",
      "Epoch: 8 Batch: 1000 Loss: 0.39864\n",
      "\tValidation Loss: 0.52908\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.74\n",
      "Epoch: 9 Batch: 1000 Loss: 0.39302\n",
      "\tValidation Loss: 0.47963\n",
      "\tOverall Validation Accuracy: 0.81 ; and for evidence only: 0.82\n",
      "Epoch: 10 Batch: 1000 Loss: 0.38608\n",
      "\tValidation Loss: 0.42646\n",
      "\tOverall Validation Accuracy: 0.81 ; and for evidence only: 0.83\n",
      "\tSaving a better model...\n",
      "Epoch: 11 Batch: 1000 Loss: 0.3793\n",
      "\tValidation Loss: 0.43123\n",
      "\tOverall Validation Accuracy: 0.77 ; and for evidence only: 0.82\n",
      "Epoch: 12 Batch: 1000 Loss: 0.3716\n",
      "\tValidation Loss: 0.35569\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.84\n",
      "\tSaving a better model...\n",
      "Epoch: 13 Batch: 1000 Loss: 0.36179\n",
      "\tValidation Loss: 0.43364\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.8\n",
      "Epoch: 14 Batch: 1000 Loss: 0.36402\n",
      "\tValidation Loss: 0.39281\n",
      "\tOverall Validation Accuracy: 0.81 ; and for evidence only: 0.87\n",
      "Epoch: 15 Batch: 1000 Loss: 0.35786\n",
      "\tValidation Loss: 0.42631\n",
      "\tOverall Validation Accuracy: 0.84 ; and for evidence only: 0.78\n",
      "Epoch: 16 Batch: 1000 Loss: 0.3517\n",
      "\tValidation Loss: 0.34112\n",
      "\tOverall Validation Accuracy: 0.84 ; and for evidence only: 0.85\n",
      "\tSaving a better model...\n",
      "Epoch: 17 Batch: 1000 Loss: 0.33487\n",
      "\tValidation Loss: 0.51156\n",
      "\tOverall Validation Accuracy: 0.84 ; and for evidence only: 0.78\n",
      "Epoch: 18 Batch: 1000 Loss: 0.34277\n",
      "\tValidation Loss: 0.42535\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.84\n",
      "Epoch: 19 Batch: 1000 Loss: 0.3325\n",
      "\tValidation Loss: 0.46715\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.78\n",
      "Epoch: 20 Batch: 1000 Loss: 0.32332\n",
      "\tValidation Loss: 0.41449\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.82\n",
      "Epoch: 21 Batch: 1000 Loss: 0.32153\n",
      "\tValidation Loss: 0.4673\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.8\n",
      "Epoch: 22 Batch: 1000 Loss: 0.31719\n",
      "\tValidation Loss: 0.65674\n",
      "\tOverall Validation Accuracy: 0.84 ; and for evidence only: 0.72\n",
      "Epoch: 23 Batch: 1000 Loss: 0.31963\n",
      "\tValidation Loss: 0.47565\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.82\n",
      "Epoch: 24 Batch: 1000 Loss: 0.31716\n",
      "\tValidation Loss: 0.39718\n",
      "\tOverall Validation Accuracy: 0.83 ; and for evidence only: 0.84\n",
      "Epoch: 25 Batch: 1000 Loss: 0.30894\n",
      "\tValidation Loss: 0.46547\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.77\n",
      "Epoch: 26 Batch: 1000 Loss: 0.30035\n",
      "\tValidation Loss: 0.55717\n",
      "\tOverall Validation Accuracy: 0.82 ; and for evidence only: 0.79\n",
      "Epoch: 27 Batch: 1000 Loss: 0.28686\n",
      "\tValidation Loss: 0.48829\n",
      "\tOverall Validation Accuracy: 0.86 ; and for evidence only: 0.82\n",
      "Epoch: 28 Batch: 1000 Loss: 0.28538\n",
      "\tValidation Loss: 0.50215\n",
      "\tOverall Validation Accuracy: 0.87 ; and for evidence only: 0.78\n",
      "Epoch: 29 Batch: 1000 Loss: 0.29283\n",
      "\tValidation Loss: 0.55556\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.78\n",
      "Epoch: 30 Batch: 1000 Loss: 0.28119\n",
      "\tValidation Loss: 0.35711\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.86\n",
      "Epoch: 31 Batch: 1000 Loss: 0.2766\n",
      "\tValidation Loss: 0.37328\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.87\n",
      "Epoch: 32 Batch: 1000 Loss: 0.28138\n",
      "\tValidation Loss: 0.52016\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.79\n",
      "Epoch: 33 Batch: 1000 Loss: 0.2764\n",
      "\tValidation Loss: 0.39073\n",
      "\tOverall Validation Accuracy: 0.87 ; and for evidence only: 0.82\n",
      "Epoch: 34 Batch: 1000 Loss: 0.27557\n",
      "\tValidation Loss: 0.38951\n",
      "\tOverall Validation Accuracy: 0.86 ; and for evidence only: 0.88\n",
      "Epoch: 35 Batch: 1000 Loss: 0.26738\n",
      "\tValidation Loss: 0.41299\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.82\n",
      "Epoch: 36 Batch: 1000 Loss: 0.26594\n",
      "\tValidation Loss: 0.56472\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.77\n",
      "Epoch: 37 Batch: 1000 Loss: 0.26041\n",
      "\tValidation Loss: 0.48758\n",
      "\tOverall Validation Accuracy: 0.86 ; and for evidence only: 0.82\n",
      "Epoch: 38 Batch: 1000 Loss: 0.25306\n",
      "\tValidation Loss: 0.53909\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.8\n",
      "Epoch: 39 Batch: 1000 Loss: 0.26134\n",
      "\tValidation Loss: 0.52132\n",
      "\tOverall Validation Accuracy: 0.84 ; and for evidence only: 0.82\n",
      "Epoch: 40 Batch: 1000 Loss: 0.25341\n",
      "\tValidation Loss: 0.43477\n",
      "\tOverall Validation Accuracy: 0.86 ; and for evidence only: 0.84\n",
      "Epoch: 41 Batch: 1000 Loss: 0.25094\n",
      "\tValidation Loss: 0.55377\n",
      "\tOverall Validation Accuracy: 0.84 ; and for evidence only: 0.82\n",
      "Epoch: 42 Batch: 1000 Loss: 0.25671\n",
      "\tValidation Loss: 0.49063\n",
      "\tOverall Validation Accuracy: 0.89 ; and for evidence only: 0.77\n",
      "Epoch: 43 Batch: 1000 Loss: 0.24117\n",
      "\tValidation Loss: 0.53729\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.75\n",
      "Epoch: 44 Batch: 1000 Loss: 0.24307\n",
      "\tValidation Loss: 0.48864\n",
      "\tOverall Validation Accuracy: 0.86 ; and for evidence only: 0.82\n",
      "Epoch: 45 Batch: 1000 Loss: 0.24096\n",
      "\tValidation Loss: 0.47519\n",
      "\tOverall Validation Accuracy: 0.83 ; and for evidence only: 0.83\n",
      "Epoch: 46 Batch: 1000 Loss: 0.24673\n",
      "\tValidation Loss: 0.64918\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.72\n",
      "Epoch: 47 Batch: 1000 Loss: 0.23705\n",
      "\tValidation Loss: 0.54673\n",
      "\tOverall Validation Accuracy: 0.87 ; and for evidence only: 0.77\n",
      "Epoch: 48 Batch: 1000 Loss: 0.23485\n",
      "\tValidation Loss: 0.43001\n",
      "\tOverall Validation Accuracy: 0.91 ; and for evidence only: 0.82\n",
      "Epoch: 49 Batch: 1000 Loss: 0.22644\n",
      "\tValidation Loss: 0.47661\n",
      "\tOverall Validation Accuracy: 0.89 ; and for evidence only: 0.8\n",
      "Epoch: 50 Batch: 1000 Loss: 0.22264\n",
      "\tValidation Loss: 0.47032\n",
      "\tOverall Validation Accuracy: 0.87 ; and for evidence only: 0.85\n",
      "Epoch: 51 Batch: 1000 Loss: 0.22693\n",
      "\tValidation Loss: 0.54724\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.81\n",
      "Epoch: 52 Batch: 1000 Loss: 0.22351\n",
      "\tValidation Loss: 0.60174\n",
      "\tOverall Validation Accuracy: 0.86 ; and for evidence only: 0.72\n",
      "Epoch: 53 Batch: 1000 Loss: 0.21747\n",
      "\tValidation Loss: 0.65316\n",
      "\tOverall Validation Accuracy: 0.86 ; and for evidence only: 0.73\n",
      "Epoch: 54 Batch: 1000 Loss: 0.21949\n",
      "\tValidation Loss: 0.50549\n",
      "\tOverall Validation Accuracy: 0.88 ; and for evidence only: 0.78\n",
      "Epoch: 55 Batch: 1000 Loss: 0.22091\n",
      "\tValidation Loss: 0.58484\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.77\n",
      "Epoch: 56 Batch: 1000 Loss: 0.21153\n",
      "\tValidation Loss: 0.66663\n",
      "\tOverall Validation Accuracy: 0.85 ; and for evidence only: 0.74\n",
      "Epoch: 57 Batch: 1000 Loss: 0.20501\n",
      "\tValidation Loss: 0.39631\n",
      "\tOverall Validation Accuracy: 0.9 ; and for evidence only: 0.84\n",
      "Epoch: 58 Batch: 1000 Loss: 0.21283\n",
      "\tValidation Loss: 0.49716\n",
      "\tOverall Validation Accuracy: 0.89 ; and for evidence only: 0.81\n",
      "Epoch: 59 Batch: 1000 Loss: 0.20605\n",
      "\tValidation Loss: 0.64105\n",
      "\tOverall Validation Accuracy: 0.87 ; and for evidence only: 0.77\n",
      "Epoch: 60 Batch: 1000 Loss: 0.21244\n",
      "\tValidation Loss: 0.40827\n",
      "\tOverall Validation Accuracy: 0.89 ; and for evidence only: 0.86\n",
      "Epoch: 61 Batch: 1000 Loss: 0.21257\n",
      "\tValidation Loss: 0.58968\n",
      "\tOverall Validation Accuracy: 0.91 ; and for evidence only: 0.78\n",
      "Epoch: 62 Batch: 1000 Loss: 0.20268\n",
      "\tValidation Loss: 0.57537\n",
      "\tOverall Validation Accuracy: 0.87 ; and for evidence only: 0.8\n",
      "Epoch: 63 Batch: 7 Loss: 0.19081\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eb75dd434c89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcontinue_from_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtot_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m75\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtot_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;31m#Train(network.to(\"cuda\"), bs=10, epochs=5, batches_per_epoch=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-eb75dd434c89>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(network, bs, epochs, batches_per_epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTrainingBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mevidences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d33a041d1225>\u001b[0m in \u001b[0;36mgetTrainingBatch\u001b[0;34m(bs, validation)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_evidentiary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnev_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_evidentiary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0m_base_tokens_ne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0m_segment_tokens_ne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Train(network, bs = 24, epochs=30, batches_per_epoch=10000):\n",
    "\n",
    "    val_min = 1000\n",
    "    if (continue_from_prev):\n",
    "        val_min = np.min(epoch_vals)\n",
    "    for k in range(epochs):\n",
    "        \n",
    "        batch_losses = []\n",
    "        \n",
    "        for i in range(batches_per_epoch):\n",
    "            tokens, segments, att_mask, classes = getTrainingBatch(bs=bs)\n",
    "            y_ = network.forward(tokens, segments, att_mask)\n",
    "            #evidences = classes >= 1\n",
    "            #non_evidences = classes == 0\n",
    "            optimizer.zero_grad()\n",
    "            #loss1 = lossFn(F.log_softmax(y_[evidences], dim=-1), classes[evidences].cuda())\n",
    "            #loss2 = lossFn(F.log_softmax(y_[non_evidences], dim = -1), classes[non_evidences].cuda())\n",
    "            #f_loss = 0.75*loss1 + 0.25*loss2\n",
    "            f_loss = getLoss(y_, classes)\n",
    "            batch_losses.append(f_loss.data.item())\n",
    "            print(\"Epoch:\", k+1, \n",
    "                  \"Batch:\", i+1, \n",
    "                  \"Loss:\", np.round(np.mean(batch_losses),5), \n",
    "                  end=\"\\r\")\n",
    "            f_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_losses.append(np.mean(batch_losses))\n",
    "        val_loss, acc, evid_acc = validate(network, num_batches=10)\n",
    "        \n",
    "        epoch_vals.append(val_loss)\n",
    "        epoch_accs.append(acc)\n",
    "        epoch_evid.append(evid_acc)\n",
    "        \n",
    "        print(\"\\n\\tValidation Loss:\", np.round(val_loss,5))\n",
    "        print(\"\\tOverall Validation Accuracy:\", np.round(acc,2), \"; and for evidence only:\", np.round(evid_acc,2))\n",
    "        \n",
    "        if (val_loss < val_min):\n",
    "            print(\"\\tSaving a better model...\")\n",
    "            torch.save(network, \"./ReFE_val_save.h5\")\n",
    "            val_min = val_loss\n",
    "            \n",
    "            with open(\"./saved_model_training_cycle.json\", \"w\") as f:            \n",
    "                f.write(json.dumps(\n",
    "                    {\n",
    "                        \"training_losses\":epoch_losses,\n",
    "                        \"validation_losses\":epoch_vals,\n",
    "                        \"validation_accuracy\":epoch_accs,\n",
    "                        \"evidence_accuracy\":epoch_evid        \n",
    "                    }\n",
    "                ))\n",
    "                f.close()\n",
    "        \n",
    "        with open(\"./training_cycle.json\", \"w\") as f:            \n",
    "            f.write(json.dumps(\n",
    "                {\n",
    "                    \"training_losses\":epoch_losses,\n",
    "                    \"validation_losses\":epoch_vals,\n",
    "                    \"validation_accuracy\":epoch_accs,\n",
    "                    \"evidence_accuracy\":epoch_evid        \n",
    "                }\n",
    "            ))\n",
    "            f.close()\n",
    "\n",
    "tot_epochs = 75\n",
    "if (continue_from_prev):\n",
    "    tot_epochs = 75 - len(epoch_losses)\n",
    "Train(network.to(\"cuda\"), bs=100, epochs=tot_epochs, batches_per_epoch=1000)\n",
    "#Train(network.to(\"cuda\"), bs=10, epochs=5, batches_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
