{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:00.225333Z",
     "start_time": "2019-04-13T15:14:49.205657Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "processed_data = pickle.load(open(\"../fever_processed.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep for Evidence Accumulation\n",
    "\n",
    "* The significance of a given statement as evidence to a claim/question is modelled as a classification problem\n",
    "* Any length of text (such as a sentence from a document), is appended to the claim/question in the usual way. \"CLS\" <claim/question tokens> \"SEP\" <potential/evidence tokens> \"SEP\"\n",
    "* A class is awarded to the combined string based on the following:\n",
    "    - Class 0, if the evidence tokens do not contribute to answering the question\n",
    "    - Class 1, if the evidence tokens partially answer the question\n",
    "    - Class 2, if the evidence tokens completely answer the question\n",
    "* len(claim) + len(evidence) + 3 should be <= 96 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:00.229576Z",
     "start_time": "2019-04-13T15:15:00.226955Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:50.421270Z",
     "start_time": "2019-04-13T15:15:00.231258Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108771 / 108771108771108771108771108771108771108771108771/ 108771108771108771108771/ 108771 108771108771108771108771108771108771 108771 108771 108771 / 108771108771108771 108771108771108771108771108771108771108771 108771108771108771108771108771108771/ 108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771 108771108771 108771 / 108771108771108771108771108771108771108771108771108771108771108771108771108771108771108771 108771 108771108771108771108771108771108771108771108771108771108771108771108771 / 108771108771108771 108771/ 108771108771108771 108771108771108771108771108771108771108771108771108771108771108771108771 108771108771 108771108771108771108771108771 108771108771108771108771108771/ 108771108771108771108771\r"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "classes = []\n",
    "import numpy as np\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def make_data(claim, evidence):\n",
    "    _ftokens = [\"[CLS]\"]\n",
    "    _ftokens.extend(claim)\n",
    "    _ftokens.append(\"[SEP]\")\n",
    "    _ftokens.extend(evidence)\n",
    "    _ftokens.append(\"[SEP]\")\n",
    "    while(len(_ftokens) < max_len):\n",
    "        _ftokens.append(\"[PAD]\")\n",
    "    _ftokens = _ftokens[:max_len]\n",
    "    segments = np.ones((max_len,))\n",
    "    segments[:len(claim) + 2] = 0\n",
    "    tokens = tokenizer.convert_tokens_to_ids(_ftokens)\n",
    "    return (tokens, segments)\n",
    "\n",
    "counter = 0\n",
    "for line in processed_data:\n",
    "    counter += 1\n",
    "    print(counter, \"/\", len(processed_data), end=\"\\r\")\n",
    "    for evidence in line[\"processed\"][\"evidentiary\"]:\n",
    "        lines.append(make_data(line[\"processed\"][\"claim\"], evidence))\n",
    "        if (len(line[\"processed\"][\"evidentiary\"]) == 1):\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(2)\n",
    "    for evidence in line[\"processed\"][\"non_evidentiary\"]:\n",
    "        lines.append(make_data(line[\"processed\"][\"claim\"], evidence))\n",
    "        classes.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:50.783232Z",
     "start_time": "2019-04-13T15:15:50.422998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points =  1605875\n",
      "Of which evidentiary: 201060\n",
      "Total training data points =  1445287\n",
      "Of which evidentiary: 180997\n",
      "Total testing data points =  160588\n",
      "Of which evidentiary: 20063\n"
     ]
    }
   ],
   "source": [
    "print(\"Total data points = \", len(classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(classes))\n",
    "\n",
    "training_lines = lines[:-len(classes)//10]\n",
    "training_classes = classes[:-len(classes)//10]\n",
    "\n",
    "print(\"Total training data points = \", len(training_classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(training_classes))\n",
    "\n",
    "training_evidentiary_indices = [i for i in range(len(training_classes)) if training_classes[i] > 0 ]\n",
    "training_nonevidentiary_indices = [i for i in range(len(training_classes)) if training_classes[i] == 0]\n",
    "\n",
    "testing_lines = lines[-len(classes)//10:]\n",
    "testing_classes = classes[-len(classes)//10:]\n",
    "\n",
    "testing_evidentiary_indices = [i for i in range(len(testing_classes)) if testing_classes[i] > 0 ]\n",
    "testing_nonevidentiary_indices = [i for i in range(len(testing_classes)) if testing_classes[i] == 0]\n",
    "\n",
    "print(\"Total testing data points = \", len(testing_classes))\n",
    "print(\"Of which evidentiary:\", np.count_nonzero(testing_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Fact Extraction (ReFE)\n",
    "\n",
    "* Going by the paper and the documentation, when fine-tuning bert for classification tasks, only the output of the CLS tag (index 0) needs to be used. We can ignore the rest\n",
    "* Aim here is to make it look to BERT like an entailment task. Since we are not really worried about the truth value of the claim, all we need to do is decide if a given sentence provides evidence to the claim or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:56.267034Z",
     "start_time": "2019-04-13T15:15:56.262800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_pretrained_bert import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epoch_vals = []\n",
    "epoch_accs = []\n",
    "epoch_evid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:15:58.964692Z",
     "start_time": "2019-04-13T15:15:56.945967Z"
    }
   },
   "outputs": [],
   "source": [
    "def getTrainingBatch(bs = 64, validation = False):\n",
    "    \n",
    "    evidentiary = training_evidentiary_indices\n",
    "    non_evidentiary = training_nonevidentiary_indices\n",
    "    source = training_lines\n",
    "    source_classes = training_classes\n",
    "    \n",
    "    if (validation):\n",
    "        evidentiary = testing_evidentiary_indices\n",
    "        non_evidentiary = testing_nonevidentiary_indices\n",
    "        source = testing_lines\n",
    "        source_classes = testing_classes\n",
    "    \n",
    "    #control the number of positive samples being\n",
    "    #seen by the dataset, since these will be much rarer in real life. \n",
    "    \n",
    "    min_divisor = 2\n",
    "    divisor = min_divisor\n",
    "    if (divisor < len(epoch_losses)):\n",
    "        divisor = len(epoch_losses)\n",
    "        \n",
    "    ev_total = bs // divisor\n",
    "    nev_total = bs - ev_total\n",
    "    x = np.random.randint(0, len(evidentiary), (ev_total))\n",
    "    x = np.asarray(evidentiary)[x]\n",
    "    _base_tokens = [source[index][0] for index in x]\n",
    "    _segment_tokens = [source[index][1] for index in x]\n",
    "    _classes = [source_classes[index] for index in x]\n",
    "    \n",
    "    x = np.random.randint(0, len(non_evidentiary), (nev_total))\n",
    "    x = np.asarray(non_evidentiary)[x]\n",
    "    _base_tokens_ne = [source[index][0] for index in x]\n",
    "    _segment_tokens_ne = [source[index][1] for index in x]\n",
    "    _classes_ne = [source_classes[index] for index in x]\n",
    "    \n",
    "    _base_tokens.extend(_base_tokens_ne)\n",
    "    _segment_tokens.extend(_segment_tokens_ne)\n",
    "    _classes.extend(_classes_ne)\n",
    "        \n",
    "    final_seq = [i for i in range(bs)]\n",
    "    np.random.shuffle(final_seq)\n",
    "    \n",
    "    tokens = []\n",
    "    segments = []\n",
    "    classes = []\n",
    "    for index in final_seq:\n",
    "        tokens.append(_base_tokens[index])\n",
    "        segments.append(_segment_tokens[index])\n",
    "        classes.append(_classes[index])\n",
    "    \n",
    "    classes = np.asarray(classes)\n",
    "    twos = classes == 2\n",
    "    classes[twos] = 1\n",
    "    \n",
    "    tokens = torch.LongTensor(tokens).cuda()\n",
    "    segments = torch.LongTensor(segments).cuda()\n",
    "    classes = torch.LongTensor(classes).cuda()\n",
    "    att_mask = tokens != 0\n",
    "    \n",
    "    return tokens, segments, att_mask, classes\n",
    "    \n",
    "tokens, segments, att_mask, classes = getTrainingBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoss(pred, actual, lossFn, e_weight=0.6, ne_weight=0.4):\n",
    "    evidences = actual >= 1\n",
    "    non_evidences = actual == 0\n",
    "    \"\"\"\n",
    "    loss1 = lossFn(F.log_softmax(pred[evidences], dim=-1), actual[evidences].cuda())\n",
    "    loss2 = lossFn(F.log_softmax(pred[non_evidences], dim = -1), actual[non_evidences].cuda())\n",
    "    e_trg_losses.append(loss1)\n",
    "    ne_training_losses.append(loss2)\n",
    "    \"\"\"\n",
    "    \n",
    "    return lossFn(F.log_softmax(pred, dim=-1), actual.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:16:01.538854Z",
     "start_time": "2019-04-13T15:16:01.529066Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReFE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReFE, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.out = torch.nn.Linear(768,2)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, inputs, segments, attention_masks):\n",
    "        f, pooled = self.bert(inputs, \n",
    "                         token_type_ids=segments, \n",
    "                         attention_mask=attention_masks, \n",
    "                         output_all_encoded_layers=False)\n",
    "        out_ = self.out(self.dropout(pooled))        \n",
    "        return out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_from_prev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:16:07.964348Z",
     "start_time": "2019-04-13T15:16:02.426051Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "network = None\n",
    "if (continue_from_prev):\n",
    "    network = torch.load(\"./ReFE_BestValidationLoss_save.h5\")\n",
    "    tcycle = None\n",
    "    with open(\"./saved_model_training_cycle.json\", \"r\") as f:\n",
    "        tcycle = json.loads(f.read())\n",
    "    epoch_losses = tcycle[\"training_losses\"][:-2]\n",
    "    epoch_vals = tcycle[\"validation_losses\"][:-2]\n",
    "    epoch_accs = tcycle[\"validation_accuracy\"][:-2]\n",
    "    epoch_evid = tcycle[\"evidence_accuracy\"][:-2]\n",
    "else:\n",
    "    network = ReFE()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Friends dont let friends use batch sizes > 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "lossFn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trg_losses = []\n",
    "ne_training_losses = []\n",
    "\n",
    "def _save(cause, network):\n",
    "    print(\"\\tSaving Model for Cause:\", cause)\n",
    "    torch.save(network, \"./ReFE_\" + cause + \"_save.h5\")\n",
    "    with open(\"./\" + cause + \"_training_cycle.json\", \"w\") as f:            \n",
    "        f.write(json.dumps(\n",
    "            {\n",
    "                \"training_losses\":epoch_losses,\n",
    "                \"validation_losses\":epoch_vals,\n",
    "                \"validation_accuracy\":epoch_accs,\n",
    "                \"evidence_accuracy\":epoch_evid        \n",
    "            }\n",
    "        ))\n",
    "        f.close()\n",
    "    \n",
    "def chooseModelSave(network):\n",
    "    save = False\n",
    "    if (np.min(epoch_vals) == epoch_vals[-1]):\n",
    "        cause = \"BestValidationLoss\"\n",
    "        _save(cause, network)\n",
    "    \n",
    "    if (np.max(epoch_accs) == epoch_accs[-1]):\n",
    "        cause = \"BestValidationOverallAccuracy\"\n",
    "        _save(cause, network)\n",
    "    \n",
    "    if (np.max(epoch_evid) == epoch_evid[-1]):\n",
    "        cause = \"BestValidationEvidentiaryAccuracy\"\n",
    "        _save(cause, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(network, bs=100, num_batches=5):\n",
    "    \n",
    "    classes = torch.LongTensor([]).cuda()\n",
    "    preds = torch.FloatTensor([]).cuda()\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_batches):\n",
    "            tokens, segments, att_mask, classes_ = getTrainingBatch(bs=bs, validation=True)\n",
    "            y_ = network.forward(tokens, segments, att_mask)\n",
    "            classes = torch.cat([classes, classes_], dim=0)\n",
    "            preds = torch.cat([preds, y_], dim=0)\n",
    "        \n",
    "        evidences = classes >= 1\n",
    "        f_loss = getLoss(preds, classes, lossFn)\n",
    "        pred = torch.max(preds, dim=-1)[1]\n",
    "        acc = torch.sum(pred == classes)\n",
    "        print(\"\\nY actual evidences:\",torch.sum(classes[evidences]))\n",
    "        print(\"\\nY predicted evidences:\",torch.sum(preds[evidences]))\n",
    "        acc = acc.cpu().numpy()/(bs*num_batches)\n",
    "        positives = torch.sum(pred[evidences] == classes[evidences])\n",
    "        \n",
    "        return f_loss.data.item(), acc, positives.cpu().numpy()/torch.sum(evidences).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T15:16:08.840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Batch: 115 Loss: 0.46665\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def chooseLossWeights():\n",
    "    \n",
    "    if (random.randint(0,100) % 5 == 0):\n",
    "        return 1.0, 0.0\n",
    "    elif (random.randint(0,100) % 20 == 0):\n",
    "        return 0.75, 0.25\n",
    "    \n",
    "    return 0.5, 0.5\n",
    "\n",
    "def Train(network, bs = 24, epochs=30, batches_per_epoch=10000):\n",
    "    val_min = 1000\n",
    "    if (continue_from_prev):\n",
    "        val_min = np.min(epoch_vals)\n",
    "    for k in range(epochs):\n",
    "        print(\"\")\n",
    "        batch_losses = []\n",
    "        for i in range(batches_per_epoch):\n",
    "            tokens, segments, att_mask, classes = getTrainingBatch(bs=bs)\n",
    "            y_ = network.forward(tokens, segments, att_mask)\n",
    "            optimizer.zero_grad()\n",
    "            e_w, ne_w = chooseLossWeights()\n",
    "            f_loss = getLoss(y_, classes, lossFn, e_weight=e_w, ne_weight=ne_w)\n",
    "            batch_losses.append(f_loss.data.item())\n",
    "            print(\"Epoch:\", k+1, \n",
    "                  \"Batch:\", i+1, \n",
    "                  \"Loss:\", np.round(np.mean(batch_losses),5), \n",
    "                  end=\"\\r\")\n",
    "            f_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_losses.append(np.mean(batch_losses))\n",
    "        val_loss, acc, evid_acc = validate(network, num_batches=10)\n",
    "        \n",
    "        epoch_vals.append(val_loss)\n",
    "        epoch_accs.append(acc)\n",
    "        epoch_evid.append(evid_acc)\n",
    "        \n",
    "        print(\"\\n\\tValidation Loss:\", np.round(val_loss,5))\n",
    "        print(\"\\tOverall Validation Accuracy:\", np.round(acc,2), \"; and for evidence only:\", np.round(evid_acc,2))\n",
    "        \n",
    "        if (val_loss < val_min):\n",
    "            val_min = val_loss\n",
    "            \n",
    "        chooseModelSave(network)\n",
    "        \n",
    "        with open(\"./training_cycle.json\", \"w\") as f:            \n",
    "            f.write(json.dumps(\n",
    "                {\n",
    "                    \"training_losses\":epoch_losses,\n",
    "                    \"validation_losses\":epoch_vals,\n",
    "                    \"validation_accuracy\":epoch_accs,\n",
    "                    \"evidence_accuracy\":epoch_evid        \n",
    "                }\n",
    "            ))\n",
    "            f.close()\n",
    "\n",
    "tot_epochs = 10\n",
    "\"\"\"\n",
    "if (continue_from_prev):\n",
    "    tot_epochs = 75 - len(epoch_losses)\n",
    "\"\"\"\n",
    "Train(network.to(\"cuda\"), bs=100, epochs=tot_epochs, batches_per_epoch=500)\n",
    "#Train(network.to(\"cuda\"), bs=10, epochs=5, batches_per_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testingBatch(bs = 100):\n",
    "    source = testing_lines\n",
    "    source_classes = testing_classes\n",
    "    x = np.random.randint(0, len(testing_lines), (bs,))\n",
    "    _tokens = [source[index][0] for index in x]\n",
    "    _segments = [source[index][1] for index in x]\n",
    "    _classes = [source_classes[index] for index in x]\n",
    "    \n",
    "    _classes = np.asarray(_classes)\n",
    "    twos = _classes == 2\n",
    "    _classes[twos] = 1\n",
    "    \n",
    "    tokens = torch.LongTensor(_tokens).cuda()\n",
    "    segments = torch.LongTensor(_segments).cuda()\n",
    "    classes = torch.LongTensor(_classes).cuda()\n",
    "    att_mask = tokens != 0\n",
    "    \n",
    "    return tokens, segments, att_mask, classes\n",
    "    \n",
    "t, s, a, c = testingBatch()\n",
    "print(t.size())\n",
    "print(s.size())\n",
    "print(c.size())\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(network, bs=100, num_batches=10):\n",
    "    \n",
    "    classes = torch.LongTensor([]).cuda()\n",
    "    preds = torch.FloatTensor([]).cuda()\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_batches):\n",
    "            tokens, segments, att_mask, classes_ = testingBatch(bs=bs)\n",
    "            y_ = network.forward(tokens, segments, att_mask)\n",
    "            classes = torch.cat([classes, classes_], dim=0)\n",
    "            preds = torch.cat([preds, y_], dim=0)\n",
    "        \n",
    "        evidences = classes >= 1\n",
    "        f_loss = getLoss(preds, classes, lossFn)\n",
    "        pred = torch.max(preds, dim=-1)[1]\n",
    "        acc = torch.sum(pred == classes)\n",
    "        acc = acc.cpu().numpy()/(bs*num_batches)\n",
    "        positives = torch.sum(pred[evidences] == classes[evidences])\n",
    "        \n",
    "        return f_loss.data.item(), acc, positives.cpu().numpy()/torch.sum(evidences).cpu().numpy(), preds, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, acc, p_acc, y_, y = validate(network)\n",
    "y_ = F.softmax(y_, dim=-1)\n",
    "y_ = torch.max(y_, dim=-1)[1]\n",
    "\n",
    "act_1 = y == 1\n",
    "act_2 = y_ == 1\n",
    "#print(act_1)\n",
    "#print(act_2)\n",
    "print(torch.sum(act_1 != act_2), torch.sum(act_1))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
