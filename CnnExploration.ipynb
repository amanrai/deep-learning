{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T07:55:37.432152Z",
     "start_time": "2019-04-24T07:55:37.426745Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"../../../Data/DMQA/cnn_stories/cnn/stories/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T08:00:04.788114Z",
     "start_time": "2019-04-24T07:55:37.789521Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "files = listdir(data_path)\n",
    "print(len(files))\n",
    "\n",
    "_all_text = []\n",
    "for file in files:\n",
    "    with open(data_path + file, \"r\") as f:\n",
    "        _all_text.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T08:00:06.078257Z",
     "start_time": "2019-04-24T08:00:04.790456Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "import numpy as np\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T08:00:06.082488Z",
     "start_time": "2019-04-24T08:00:06.080080Z"
    }
   },
   "outputs": [],
   "source": [
    "stride = 50\n",
    "max_len = 450\n",
    "max_tokenized_len = 511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T08:15:01.005562Z",
     "start_time": "2019-04-24T08:02:12.583399Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, len(files), (100,))\n",
    "lens = []\n",
    "count = 0\n",
    "dps = []\n",
    "counter = 0\n",
    "for text in _all_text:\n",
    "    counter += 1\n",
    "    split = text.index(\"@highlight\")\n",
    "    story = text[:split]\n",
    "    summary = text[split:]\n",
    "    summary = summary.replace(\"@highlight\\n\", \"\")\n",
    "    summary = summary.replace(\"\\n+\", \"\\n\")\n",
    "    lines = np.asarray(summary.split(\"\\n\"))\n",
    "    valid_lines = [len(line) > 5 for line in lines]\n",
    "    summary = lines[valid_lines]\n",
    "    lines = np.asarray(story.split(\"\\n\"))\n",
    "    valid_lines = [len(line) > 5 for line in lines]\n",
    "    story = lines[valid_lines]\n",
    "    story = \" \".join(story)\n",
    "    summary = \". \".join(summary) + \".\"\n",
    "    summary = summary.replace(\"NEW:\", \"\")\n",
    "    story = \" \".join(story.split()[:max_len])\n",
    "\n",
    "    _sto_tokens = tokenizer.tokenize(story)\n",
    "    _sto_tokens = _sto_tokens[:max_tokenized_len]\n",
    "    _sum_tokens = tokenizer.tokenize(summary)\n",
    "    pointers = []\n",
    "    for i in range(len(_sum_tokens)):\n",
    "        token = _sum_tokens[i]\n",
    "        if (any(char.isdigit() for char in token)):\n",
    "            pointers.append(i)\n",
    "    \n",
    "    _story = tokenizer.convert_tokens_to_ids(_sto_tokens)\n",
    "    _summary = tokenizer.convert_tokens_to_ids(_sum_tokens)\n",
    "    dp = {\n",
    "        \"story\":story,\n",
    "        \"summary\":summary, \n",
    "        \"story_tokens\":_story, \n",
    "        \"summary_tokens\":_summary,\n",
    "        \"pointers\":pointers\n",
    "    }\n",
    "    dps.append(dp)\n",
    "    print(counter, \"/\", len(_all_text), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T08:15:42.169151Z",
     "start_time": "2019-04-24T08:15:40.942283Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(dps, open(\"../../../Data/DMQA/cnn_tokenized.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
