{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T06:09:57.988313Z",
     "start_time": "2019-04-11T06:09:57.874010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aman/dl\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T06:09:59.030101Z",
     "start_time": "2019-04-11T06:09:58.647674Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "squad_data = None\n",
    "with open(\"../squad/dataset/train-v1.1.json\", \"r\") as f:\n",
    "    squad_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T06:09:59.700924Z",
     "start_time": "2019-04-11T06:09:59.697637Z"
    }
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T07:10:51.275726Z",
     "start_time": "2019-04-11T07:09:36.595039Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'answers': [{'answer_start': 176, 'text': 'rld around it'}],\n",
      "    'id': '57309ede396df9190009621b',\n",
      "    'question': 'What makes up the sum of relations to an entity?'}\n",
      "{   'answers': [{'answer_start': 58, 'text': 'kno'}],\n",
      "    'id': '56df865956340a1900b29ceb',\n",
      "    'question': 'Would you consider aesthetic elements alone in architectural '\n",
      "                'lighting design?'}\n",
      "{   'answers': [{'answer_start': 156, 'text': 'ano'}],\n",
      "    'id': '56df95d44a1a83140091eb81',\n",
      "    'question': 'Would a lower GAI mean higher apparent saturation or '\n",
      "                'vividness of object colors?'}\n",
      "{   'answers': [{'answer_start': 223, 'text': '30s'}],\n",
      "    'id': '56df736f5ca0a614008f9a91',\n",
      "    'question': 'How many pubs existed on Union Street in the 1930s?'}\n",
      "{   'answers': [{'answer_start': 29, 'text': '250 million'}],\n",
      "    'id': '56e065a0231d4119001ac08d',\n",
      "    'question': \"How much money was spent on construction of the island's \"\n",
      "                'airport?'}\n",
      "{   'answers': [{'answer_start': 202, 'text': '286 kJ/mol'}],\n",
      "    'id': '56e07476231d4119001ac17f',\n",
      "    'question': 'For hydrogen what is the enthalpy of combustion?'}\n",
      "{   'answers': [{'answer_start': 9, 'text': '50s'}],\n",
      "    'id': '56fdcd6019033b140034cd8b',\n",
      "    'question': 'By what decade were analog computing devices rendered '\n",
      "                'obsolete?'}\n",
      "{   'answers': [{'answer_start': 550, 'text': 'dard'}],\n",
      "    'id': '5706300775f01819005e7a62',\n",
      "    'question': 'What is used to identify the begining of a valid frame of an '\n",
      "                'MP3 header?'}\n",
      "{   'answers': [{'answer_start': 1102, 'text': 'yptian Se'}],\n",
      "    'id': '57262473271a42140099d4e9',\n",
      "    'question': 'dd'}\n",
      "{   'answers': [{'answer_start': 1185, 'text': 'Buddh'}],\n",
      "    'id': '57262473271a42140099d4ea',\n",
      "    'question': 'dd'}\n",
      "{   'answers': [{'answer_start': 1090, 'text': 'the Gre'}],\n",
      "    'id': '57262473271a42140099d4ed',\n",
      "    'question': 'd'}\n",
      "{   'answers': [{'answer_start': 240, 'text': 'refor'}],\n",
      "    'id': '572628deec44d21400f3daaf',\n",
      "    'question': \"I couldn't could up with another question. But i need to fill \"\n",
      "                \"this space because I can't submit the hit. \"}\n",
      "{   'answers': [{'answer_start': 533, 'text': 'tes (3'}],\n",
      "    'id': '572628f0271a42140099d623',\n",
      "    'question': \"I couldn't could up with another question. But i need to fill \"\n",
      "                \"this space because I can't submit the hit. \"}\n",
      "{   'answers': [   {   'answer_start': 464,\n",
      "                       'text': 'orida had become \"a derelict open to the '\n",
      "                               'occupancy of every enemy, civilized or '\n",
      "                               'savage'}],\n",
      "    'id': '57265e2b5951b619008f70b6',\n",
      "    'question': 'Why did the US president say the Incursion of Florida was '\n",
      "                'neccessary'}\n",
      "{   'answers': [   {   'answer_start': 523,\n",
      "                       'text': '966 Claude R. Kirk, Jr. was elected as the '\n",
      "                               'first post-Reconstruction Republican governor, '\n",
      "                               'in an upset election'}],\n",
      "    'id': '572670f2f1498d1400e8dfb6',\n",
      "    'question': 'Who was Claude R Kirk '}\n",
      "{   'answers': [   {   'answer_start': 639,\n",
      "                       'text': '968 Edward J. Gurney, also a white '\n",
      "                               \"conservative, was elected as the state's first \"\n",
      "                               'post-reconstruction Republican US Senator'}],\n",
      "    'id': '572670f2f1498d1400e8dfb7',\n",
      "    'question': 'Who was Edward j Gurney '}\n",
      "{   'answers': [   {   'answer_start': 315,\n",
      "                       'text': 'privately funded English language schoo'}],\n",
      "    'id': '572908166aef0514001549cb',\n",
      "    'question': 'Are there any alternatives to the public school system in '\n",
      "                'Burma ?'}\n",
      "{   'answers': [   {   'answer_start': 1,\n",
      "                       'text': 'ederalism in the United States is the evolving '\n",
      "                               'relationship between state governments and the '\n",
      "                               'federal government of the United States'}],\n",
      "    'id': '5728384dff5b5019007d9f4e',\n",
      "    'question': 'What is federalism in the United States?'}\n",
      "{   'answers': [   {   'answer_start': 901,\n",
      "                       'text': '\"While the interstellar absorbing medium may '\n",
      "                               'be simply the ether, [it] is characteris'}],\n",
      "    'id': '572ebe0a03f98919007569d2',\n",
      "    'question': 'Why were experiments done on luminiferous aether in the 19 '\n",
      "                'Century?'}\n",
      "{   'answers': [{'answer_start': 50, 'text': 'ano'}],\n",
      "    'id': '572fb6f904bcaa1900d76c27',\n",
      "    'question': 'Can a DBMS be transfered to a different DBMS?'}\n",
      "{   'answers': [{'answer_start': 21, 'text': 'enrich'}],\n",
      "    'id': '57325d03b9d445190005eaab',\n",
      "    'question': 'What did John Milton do for world literature?'}\n"
     ]
    }
   ],
   "source": [
    "data = squad_data[\"data\"]\n",
    "ignore_parts = [\"#\", \",\", \".\",  \"(\", \")\", \"'\", \"\\\"\"]\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "all_datapoints = []\n",
    "for doc in data:\n",
    "    for paragraph in doc[\"paragraphs\"]:\n",
    "        text = paragraph[\"context\"]\n",
    "        tokens = text.split()\n",
    "        token_len = len(tokens)\n",
    "        tokens = \" \".join(tokens)\n",
    "        b_tokens = tokenizer.tokenize(tokens)\n",
    "        tokenized = \" \".join(b_tokens)\n",
    "        for qas in paragraph[\"qas\"]:\n",
    "            question = tokenizer.tokenize(qas[\"question\"])\n",
    "            #print(question)\n",
    "            for answer in qas[\"answers\"]:\n",
    "                try:\n",
    "                    t_answer = tokenizer.tokenize(answer[\"text\"])\n",
    "                    answer_start = tokenized.index(\" \".join(t_answer))\n",
    "                    _t = tokenized[:answer_start].split()\n",
    "                    d_t = tokenized.split()\n",
    "                except:\n",
    "                    pprint.pprint(qas, indent=4)\n",
    "                if (len(d_t) <= 512):\n",
    "                    add = True\n",
    "                    try:\n",
    "                        _start = len(_t)\n",
    "                        _end = _start + len(t_answer)\n",
    "                        #print(b_tokens[_start:_end])\n",
    "                        data_tokens = [\"[CLS]\"]\n",
    "                        data_tokens.extend(question)\n",
    "                        data_tokens.append(\"[SEP]\")\n",
    "                        data_tokens.extend(b_tokens)\n",
    "                        data_tokens.append(\"[SEP]\")\n",
    "                        _start = _start + len(question) + 2 \n",
    "                        _end = _end + len(question) + 2 \n",
    "                        #print(data_tokens, _start, _end, \"\\n\", data_tokens[_start:_end])\n",
    "                        while (len(data_tokens) < 512):\n",
    "                            data_tokens.append(\"[PAD]\")\n",
    "                        sentence_types = np.ones((512,), dtype=np.int8)\n",
    "                        sentence_types[:len(question) + 2] = 0    \n",
    "                        data_tokens = data_tokens[:512]\n",
    "                        dp = {\n",
    "                            \"doc\":b_tokens,\n",
    "                            #\"doc_tokens\":doc_token_ids,\n",
    "                            \"question\":question,\n",
    "                            #\"question_tokens\":question_token_ids,\n",
    "                            \"answer_start\":_start,\n",
    "                            \"answer_end\":_end,\n",
    "                            \"data\":{\n",
    "                                \"tokens\":tokenizer.convert_tokens_to_ids(data_tokens),\n",
    "                                \"segments\":sentence_types\n",
    "                            }\n",
    "                        }\n",
    "                    except:\n",
    "                        add = False\n",
    "                    if (add):\n",
    "                        all_datapoints.append(dp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:44:51.192575Z",
     "start_time": "2019-04-06T13:44:51.188470Z"
    }
   },
   "source": [
    "print(len(all_datapoints))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:44:56.190428Z",
     "start_time": "2019-04-06T13:44:51.447846Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "doc_lengths = [len(dp[\"doc_tokens\"]) for dp in all_datapoints]\n",
    "ques_lengths = [len(dp[\"question_tokens\"]) for dp in all_datapoints]\n",
    "doc_max_len = int(np.percentile(doc_lengths, 99.5))\n",
    "ques_max_len = int(np.percentile(ques_lengths, 99.5))\n",
    "\n",
    "for dp in all_datapoints:\n",
    "    while(len(dp[\"doc_tokens\"]) < doc_max_len):\n",
    "        dp[\"doc_tokens\"].append(0)\n",
    "    dp[\"doc_tokens\"] = dp[\"doc_tokens\"][:doc_max_len]\n",
    "    while(len(dp[\"question_tokens\"]) < ques_max_len):\n",
    "        dp[\"question_tokens\"].append(0)\n",
    "    dp[\"question_tokens\"] = dp[\"question_tokens\"][:ques_max_len]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:44:59.838306Z",
     "start_time": "2019-04-06T13:44:59.755118Z"
    }
   },
   "source": [
    "doc_lengths = [len(dp[\"doc_tokens\"]) for dp in all_datapoints]\n",
    "ques_lengths = [len(dp[\"question_tokens\"]) for dp in all_datapoints]\n",
    "\n",
    "print(np.min(doc_lengths), np.max(doc_lengths))\n",
    "print(np.min(ques_lengths), np.max(ques_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T07:14:49.424466Z",
     "start_time": "2019-04-11T07:14:47.247137Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(all_datapoints, open(\"./squad_processed_1.1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
